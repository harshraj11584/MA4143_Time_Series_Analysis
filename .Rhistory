plot(forecast(m3,level=c(75,95),h=10))
"For Baseline Model, MSE = "
baseline_error
"Model 1 MSE = "
mse(stocks,m1$fitted)
"Model 2 MSE = "
mse(stocks,m2$fitted)
"Model 3 MSE = "
mse(stocks,m3$fitted)
library(car)
library(TSA)
library(tseries)
library(ModelMetrics)
library(uroot)
library(fUnitRoots)
library(forecast)
nse_stocks <- read.csv(file = 'Dataset/nifty50.csv')
summary(nse_stocks)
# nse_stocks
#want to model the closing points for the data
dta <- nse_stocks[ c("Date","Close" ) ]
dta$Date <- as.Date(dta$Date,format="%d-%b-%Y")
summary(dta)
str(dta)
times <- dta$Date
stocks <- dta$Close
str(stocks)
str(times)
ts <- as.ts(stocks)
plot(dta,type='l')
#setting up a baseline model that predicts y(t+1) = y(t)
#any model that is good must have Mean Abs Error better than this model
n<-length(ts) #number of datapoints
y_baseline_actual <- stocks[2:n]
y_baseline_predicted <- stocks[1:n-1]
baseline_error <- mse(actual=y_baseline_actual,predicted=y_baseline_predicted)
baseline_error
#Checking Stationarity with lag 1
adf.test(x=ts , alternative="stationary", k=1)
#Checking Stationarity with lag autodetermined
adf.test(x=ts , alternative="stationary")
#Trying Box-Cox Transformation for Stationarity
ts_final.transform = BoxCox.ar(ts)
lambda = ts_final.transform$mle # estimated value of lambda based on MLE
transformed.ts_final<-bcPower(ts,lambda) # transformed TS
plot(transformed.ts_final, type = 'l',ylab="boxCox transformed") # NO Significant improvement
adf.test(transformed.ts_final)
#Tring Log Transform
plot(log(ts), ylab = 'logarithmData' , type = 'l') # No change
#Trying Differencing
plot(diff(ts),ylab='First Difference',type='l')
adf.test(diff(ts)) #Stationary
tss <- diff(ts)
# Detcting the order using ACF and PACF plots
# Should add EACF ?
acf(tss, lag.max=15, ylab =  "Auto Correlation Function",ci.type="ma") # suggests p=3
pacf(tss, lag.max=15, ylab = "Partial Auto Correlation Function") # suggests q=3
eacf(tss, ar.max=15, ma.max=15) #suggesting ARMA(1,2)
#applying armasubsets on differenced ts
result = armasubsets(y=tss,nar=10,nma=7,y.name='test',ar.method='ols')
plot(result)
#To minimize BIC, it suggests AR(3)
# M1 : conditional least squares estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS")
# M1 : maximum likelihood estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="ML")
# M1 : first CSS then ML on resulting estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS-ML")
plot( y=(m1$residuals), x=times )
densityplot(as.numeric(m1$residuals))
# M1 : conditional least squares estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS")
# M1 : maximum likelihood estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="ML")
# M1 : first CSS then ML on resulting estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS-ML")
plot( y=(m1$residuals), x=times )
densityplot(as.numeric(m1$residuals))
# M1 : conditional least squares estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS")
# M1 : maximum likelihood estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="ML")
# M1 : first CSS then ML on resulting estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS-ML")
plot( y=(m1$residuals), x=times )
densityPlot(as.numeric(m1$residuals))
# M1 : conditional least squares estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS")
# M1 : maximum likelihood estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="ML")
# M1 : first CSS then ML on resulting estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS-ML")
plot( y=(m1$residuals), x=times )
densityplot(as.numeric(m1$residuals))
library(car)
library(TSA)
library(tseries)
library(ModelMetrics)
library(uroot)
library(fUnitRoots)
library(forecast)
nse_stocks <- read.csv(file = 'Dataset/nifty50.csv')
summary(nse_stocks)
# nse_stocks
#want to model the closing points for the data
dta <- nse_stocks[ c("Date","Close" ) ]
dta$Date <- as.Date(dta$Date,format="%d-%b-%Y")
summary(dta)
str(dta)
times <- dta$Date
stocks <- dta$Close
str(stocks)
str(times)
ts <- as.ts(stocks)
plot(dta,type='l')
#want to model the closing points for the data
dta <- nse_stocks[ c("Date","Close" ) ]
dta$Date <- as.Date(dta$Date,format="%d-%b-%Y")
summary(dta)
str(dta)
times <- dta$Date
stocks <- dta$Close
str(stocks)
str(times)
ts <- as.ts(stocks)
plot(dta,type='l')
#setting up a baseline model that predicts y(t+1) = y(t)
#any model that is good must have Mean Abs Error better than this model
n<-length(ts) #number of datapoints
y_baseline_actual <- stocks[2:n]
y_baseline_predicted <- stocks[1:n-1]
baseline_error <- mse(actual=y_baseline_actual,predicted=y_baseline_predicted)
baseline_error
#Checking Stationarity with lag 1
adf.test(x=ts , alternative="stationary", k=1)
#Checking Stationarity with lag autodetermined
adf.test(x=ts , alternative="stationary")
#Trying Box-Cox Transformation for Stationarity
ts_final.transform = BoxCox.ar(ts)
lambda = ts_final.transform$mle # estimated value of lambda based on MLE
transformed.ts_final<-bcPower(ts,lambda) # transformed TS
plot(transformed.ts_final, type = 'l',ylab="boxCox transformed") # NO Significant improvement
adf.test(transformed.ts_final)
#Tring Log Transform
plot(log(ts), ylab = 'logarithmData' , type = 'l') # No change
#Trying Differencing
plot(diff(ts),ylab='First Difference',type='l')
adf.test(diff(ts)) #Stationary
tss <- diff(ts)
# Detcting the order using ACF and PACF plots
# Should add EACF ?
acf(tss, lag.max=15, ylab =  "Auto Correlation Function",ci.type="ma") # suggests p=3
pacf(tss, lag.max=15, ylab = "Partial Auto Correlation Function") # suggests q=3
eacf(tss, ar.max=15, ma.max=15) #suggesting ARMA(1,2)
#applying armasubsets on differenced ts
result = armasubsets(y=tss,nar=10,nma=7,y.name='test',ar.method='ols')
plot(result)
#To minimize BIC, it suggests AR(3)
# M1 : conditional least squares estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS")
# M1 : maximum likelihood estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="ML")
# M1 : first CSS then ML on resulting estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS-ML")
plot( y=(m1$residuals), x=times )
densityplot(as.numeric(m1$residuals))
library(car)
library(TSA)
library(ggplot2)
library(tseries)
library(ModelMetrics)
library(uroot)
library(fUnitRoots)
library(forecast)
# M1 : conditional least squares estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS")
# M1 : maximum likelihood estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="ML")
# M1 : first CSS then ML on resulting estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS-ML")
plot( y=(m1$residuals), x=times )
densityplot(as.numeric(m1$residuals))
library(car)
library(caret)
library(TSA)
library(ggplot2)
library(tseries)
library(ModelMetrics)
library(uroot)
library(fUnitRoots)
library(forecast)
nse_stocks <- read.csv(file = 'Dataset/nifty50.csv')
summary(nse_stocks)
# nse_stocks
nse_stocks <- read.csv(file = 'Dataset/nifty50.csv')
summary(nse_stocks)
# nse_stocks
# M1 : conditional least squares estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS")
# M1 : maximum likelihood estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="ML")
# M1 : first CSS then ML on resulting estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS-ML")
plot( y=(m1$residuals), x=times )
densityplot(as.numeric(m1$residuals))
acf(m1$residuals,lag.max=20,ci.type="ma") #Residuals are uncorrelated
pacf(m1$residuals, lag.max=20)
qqnorm(m1$residuals)
qqline(m1$residuals)
"Sum of Squares of Residuals for ARIMA(1,1,2) = "
sum((m1$residuals)^2)
tsdiag(m1,  gof = 15,omit.initial=F)
# M2 : conditional least squares estimates :
m2 <- Arima(ts,order=c(3,1,3),include.mean=TRUE,method="CSS")
# M2 : maximum likelihood estimates :
m2 <- Arima(ts,order=c(3,1,3),include.mean=TRUE,method="ML")
# M2 : first CSS then ML on resulting estimates :
m2 <- Arima(ts,order=c(3,1,3),include.mean=TRUE,method="CSS-ML")
plot( y=(m2$residuals), x=times )
densityplot(as.numeric(m2$residuals))
acf(m2$residuals,lag.max=20,ci.type="ma")
pacf(m2$residuals, lag.max=20)
qqnorm(m2$residuals)
qqline(m2$residuals)
"Sum of Squares of Residuals for ARIMA(3,1,3) = "
sum((m2$residuals)^2)
tsdiag(m2,  gof = 15,omit.initial=F)
# M3 : conditional least squares estimates :
m3 <- Arima(ts,order=c(3,1,0),include.mean=TRUE,method="CSS")
# M3 : maximum likelihood estimates :
m3 <- Arima(ts,order=c(3,1,0),include.mean=TRUE,method="ML")
# M3 : first CSS then ML on resulting estimates :
m3 <- Arima(ts,order=c(3,1,0),include.mean=TRUE,method="CSS-ML")
plot( y=(m3$residuals), x=times )
densityplot(as.numeric(m3$residuals))
acf(m3$residuals,lag.max=20,ci.type="ma")
pacf(m3$residuals, lag.max=20)
qqnorm(m3$residuals)
qqline(m3$residuals)
"Sum of Squares of Residuals for ARIMA(3,1,0) = "
sum((m3$residuals)^2)
tsdiag(m3,  gof = 15,omit.initial=F)
# For Ljung-Box Test, p-values > 0.05 => Residuals are Not Correlated
library(car)
library(caret)
library(TSA)
library(tseries)
library(ModelMetrics)
library(uroot)
library(fUnitRoots)
library(forecast)
nse_stocks <- read.csv(file = 'Dataset/nifty50.csv')
summary(nse_stocks)
# nse_stocks
#want to model the closing points for the data
dta <- nse_stocks[ c("Date","Close" ) ]
dta$Date <- as.Date(dta$Date,format="%d-%b-%Y")
summary(dta)
str(dta)
times <- dta$Date
stocks <- dta$Close
str(stocks)
str(times)
ts <- as.ts(stocks)
plot(dta,type='l')
#setting up a baseline model that predicts y(t+1) = y(t)
#any model that is good must have Mean Abs Error better than this model
n<-length(ts) #number of datapoints
y_baseline_actual <- stocks[2:n]
y_baseline_predicted <- stocks[1:n-1]
baseline_error <- mse(actual=y_baseline_actual,predicted=y_baseline_predicted)
baseline_error
#Checking Stationarity with lag 1
adf.test(x=ts , alternative="stationary", k=1)
#Checking Stationarity with lag autodetermined
adf.test(x=ts , alternative="stationary")
#Trying Box-Cox Transformation for Stationarity
ts_final.transform = BoxCox.ar(ts)
lambda = ts_final.transform$mle # estimated value of lambda based on MLE
transformed.ts_final<-bcPower(ts,lambda) # transformed TS
plot(transformed.ts_final, type = 'l',ylab="boxCox transformed") # NO Significant improvement
adf.test(transformed.ts_final)
#Tring Log Transform
plot(log(ts), ylab = 'logarithmData' , type = 'l') # No change
#Trying Differencing
plot(diff(ts),ylab='First Difference',type='l')
adf.test(diff(ts)) #Stationary
tss <- diff(ts)
# Detcting the order using ACF and PACF plots
# Should add EACF ?
acf(tss, lag.max=15, ylab =  "Auto Correlation Function",ci.type="ma") # suggests p=3
pacf(tss, lag.max=15, ylab = "Partial Auto Correlation Function") # suggests q=3
eacf(tss, ar.max=15, ma.max=15) #suggesting ARMA(1,2)
#applying armasubsets on differenced ts
result = armasubsets(y=tss,nar=10,nma=7,y.name='test',ar.method='ols')
plot(result)
#To minimize BIC, it suggests AR(3)
# M1 : conditional least squares estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS")
# M1 : maximum likelihood estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="ML")
# M1 : first CSS then ML on resulting estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS-ML")
plot( y=(m1$residuals), x=times )
densityplot(as.numeric(m1$residuals))
acf(m1$residuals,lag.max=20,ci.type="ma") #Residuals are uncorrelated
pacf(m1$residuals, lag.max=20)
qqnorm(m1$residuals)
qqline(m1$residuals)
"Sum of Squares of Residuals for ARIMA(1,1,2) = "
sum((m1$residuals)^2)
tsdiag(m1,  gof = 15,omit.initial=F)
# M2 : conditional least squares estimates :
m2 <- Arima(ts,order=c(3,1,3),include.mean=TRUE,method="CSS")
# M2 : maximum likelihood estimates :
m2 <- Arima(ts,order=c(3,1,3),include.mean=TRUE,method="ML")
# M2 : first CSS then ML on resulting estimates :
m2 <- Arima(ts,order=c(3,1,3),include.mean=TRUE,method="CSS-ML")
plot( y=(m2$residuals), x=times )
densityplot(as.numeric(m2$residuals))
acf(m2$residuals,lag.max=20,ci.type="ma")
pacf(m2$residuals, lag.max=20)
qqnorm(m2$residuals)
qqline(m2$residuals)
"Sum of Squares of Residuals for ARIMA(3,1,3) = "
sum((m2$residuals)^2)
tsdiag(m2,  gof = 15,omit.initial=F)
# M3 : conditional least squares estimates :
m3 <- Arima(ts,order=c(3,1,0),include.mean=TRUE,method="CSS")
# M3 : maximum likelihood estimates :
m3 <- Arima(ts,order=c(3,1,0),include.mean=TRUE,method="ML")
# M3 : first CSS then ML on resulting estimates :
m3 <- Arima(ts,order=c(3,1,0),include.mean=TRUE,method="CSS-ML")
plot( y=(m3$residuals), x=times )
densityplot(as.numeric(m3$residuals))
acf(m3$residuals,lag.max=20,ci.type="ma")
pacf(m3$residuals, lag.max=20)
qqnorm(m3$residuals)
qqline(m3$residuals)
"Sum of Squares of Residuals for ARIMA(3,1,0) = "
sum((m3$residuals)^2)
tsdiag(m3,  gof = 15,omit.initial=F)
# For Ljung-Box Test, p-values > 0.05 => Residuals are Not Correlated
plot(times,stocks,type='l')
points(times,m1$fitted,pch='*',col="dark red")
plot(times,stocks,type='l')
points(times,m2$fitted,pch='*',col="dark blue")
plot(times,stocks,type='l')
points(times,m3$fitted,pch='*',col="dark green")
plot(forecast(m1,level=c(75,95),h=10))
plot(forecast(m2,level=c(75,95),h=10))
plot(forecast(m3,level=c(75,95),h=10))
"For Baseline Model, MSE = "
baseline_error
"Model 1 MSE"
mse(stocks,m1$fitted)
"Model 2 MSE"
mse(stocks,m2$fitted)
"Model 3 MSE"
mse(stocks,m3$fitted)
library(car)
library(caret)
library(TSA)
library(tseries)
library(ModelMetrics)
library(uroot)
library(fUnitRoots)
library(forecast)
nse_stocks <- read.csv(file = 'Dataset/nifty50.csv')
summary(nse_stocks)
# nse_stocks
#want to model the closing points for the data
dta <- nse_stocks[ c("Date","Close" ) ]
dta$Date <- as.Date(dta$Date,format="%d-%b-%Y")
summary(dta)
str(dta)
times <- dta$Date
stocks <- dta$Close
str(stocks)
str(times)
ts <- as.ts(stocks)
plot(dta,type='l')
#setting up a baseline model that predicts y(t+1) = y(t)
#any model that is good must have Mean Abs Error better than this model
n<-length(ts) #number of datapoints
y_baseline_actual <- stocks[2:n]
y_baseline_predicted <- stocks[1:n-1]
baseline_error <- mse(actual=y_baseline_actual,predicted=y_baseline_predicted)
baseline_error
#Checking Stationarity with lag 1
adf.test(x=ts , alternative="stationary", k=1)
#Checking Stationarity with lag autodetermined
adf.test(x=ts , alternative="stationary")
#Trying Box-Cox Transformation for Stationarity
ts_final.transform = BoxCox.ar(ts)
lambda = ts_final.transform$mle # estimated value of lambda based on MLE
transformed.ts_final<-bcPower(ts,lambda) # transformed TS
plot(transformed.ts_final, type = 'l',ylab="boxCox transformed") # NO Significant improvement
adf.test(transformed.ts_final)
#Trying Log Transform
plot(log(ts), ylab = 'logarithmData' , type = 'l') # No change
#Trying Differencing
plot(diff(ts),ylab='First Difference',type='l')
adf.test(diff(ts)) #Stationary
tss <- diff(ts)
adfTest(x=ts)
adfTest(x=ts)
#Checking Stationarity with lag 1
adf.test(x=ts , alternative="stationary", k=1)
#Checking Stationarity with lag autodetermined
adf.test(x=ts , alternative="stationary")
#Trying Box-Cox Transformation for Stationarity
ts_final.transform = BoxCox.ar(ts)
lambda = ts_final.transform$mle # estimated value of lambda based on MLE
transformed.ts_final<-bcPower(ts,lambda) # transformed TS
plot(transformed.ts_final, type = 'l',ylab="boxCox transformed") # NO Significant improvement
adf.test(transformed.ts_final)
#Trying Log Transform
plot(log(ts), ylab = 'logarithmData' , type = 'l') # No change
#Trying Differencing
plot(diff(ts),ylab='First Difference',type='l')
adf.test(diff(ts)) #Stationary
tss <- diff(ts)
adfTest(diff(ts))
adfTest(diff(ts),type='nc')
# Detcting the order using ACF and PACF plots
# Should add EACF ?
acf(tss, lag.max=15, ylab =  "Auto Correlation Function",ci.type="ma") # suggests p=3
pacf(tss, lag.max=15, ylab = "Partial Auto Correlation Function") # suggests q=3
eacf(tss, ar.max=15, ma.max=15) #suggesting ARMA(1,2)
#applying armasubsets on differenced ts
result = armasubsets(y=tss,nar=10,nma=7,y.name='test',ar.method='ols')
plot(result)
#To minimize BIC, it suggests AR(3)
# M1 : conditional least squares estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS")
# M1 : maximum likelihood estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="ML")
# M1 : first CSS then ML on resulting estimates :
m1 <- Arima(ts,order=c(1,1,2),include.mean=TRUE,method="CSS-ML")
plot( y=(m1$residuals), x=times )
densityplot(as.numeric(m1$residuals))
acf(m1$residuals,lag.max=20,ci.type="ma") #Residuals are uncorrelated
pacf(m1$residuals, lag.max=20)
qqnorm(m1$residuals)
qqline(m1$residuals)
"Sum of Squares of Residuals for ARIMA(1,1,2) = "
sum((m1$residuals)^2)
tsdiag(m1,  gof = 15,omit.initial=F)
# M2 : conditional least squares estimates :
m2 <- Arima(ts,order=c(3,1,3),include.mean=TRUE,method="CSS")
# M2 : maximum likelihood estimates :
m2 <- Arima(ts,order=c(3,1,3),include.mean=TRUE,method="ML")
# M2 : first CSS then ML on resulting estimates :
m2 <- Arima(ts,order=c(3,1,3),include.mean=TRUE,method="CSS-ML")
plot( y=(m2$residuals), x=times )
densityplot(as.numeric(m2$residuals))
acf(m2$residuals,lag.max=20,ci.type="ma")
pacf(m2$residuals, lag.max=20)
qqnorm(m2$residuals)
qqline(m2$residuals)
"Sum of Squares of Residuals for ARIMA(3,1,3) = "
sum((m2$residuals)^2)
tsdiag(m2,  gof = 15,omit.initial=F)
# M3 : conditional least squares estimates :
m3 <- Arima(ts,order=c(3,1,0),include.mean=TRUE,method="CSS")
# M3 : maximum likelihood estimates :
m3 <- Arima(ts,order=c(3,1,0),include.mean=TRUE,method="ML")
# M3 : first CSS then ML on resulting estimates :
m3 <- Arima(ts,order=c(3,1,0),include.mean=TRUE,method="CSS-ML")
plot( y=(m3$residuals), x=times )
densityplot(as.numeric(m3$residuals))
acf(m3$residuals,lag.max=20,ci.type="ma")
pacf(m3$residuals, lag.max=20)
qqnorm(m3$residuals)
qqline(m3$residuals)
"Sum of Squares of Residuals for ARIMA(3,1,0) = "
sum((m3$residuals)^2)
tsdiag(m3,  gof = 15,omit.initial=F)
# For Ljung-Box Test, p-values > 0.05 => Residuals are Not Correlated
plot(times,stocks,type='l')
points(times,m1$fitted,pch='*',col="dark red")
plot(times,stocks,type='l')
points(times,m2$fitted,pch='*',col="dark blue")
plot(times,stocks,type='l')
points(times,m3$fitted,pch='*',col="dark green")
plot(forecast(m1,level=c(75,95),h=10))
plot(forecast(m2,level=c(75,95),h=10))
plot(forecast(m3,level=c(75,95),h=10))
"For Baseline Model, MSE = "
baseline_error
"Model 1 MSE"
mse(stocks,m1$fitted)
"Model 2 MSE"
mse(stocks,m2$fitted)
"Model 3 MSE"
mse(stocks,m3$fitted)
plot(forecast(m1,level=c(75,95),h=10))
plot(forecast(m2,level=c(75,95),h=10))
plot(forecast(m3,level=c(75,95),h=10))
"For Baseline Model, MSE = "
baseline_error
"Model 1 MSE"
mse(stocks,m1$fitted)
m1
"Model 2 MSE"
mse(stocks,m2$fitted)
m2
"Model 3 MSE"
mse(stocks,m3$fitted)
m3
n
